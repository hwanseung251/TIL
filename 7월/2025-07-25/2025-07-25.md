📚 관통PJT-01 (도서)

## 그룹 A

### 요구사항 번호: F01, F02, F03, F04, F05

---

### 📁 사용한 파일 목록

- `problem_A1.py`: 도서 제목 리스트 출력
- `problem_A2.py`: 도서 판매가의 평균 계산
- `problem_A3.py`: 고객 리뷰 순위의 평균 계산
- `problem_A4.py`: 도서 제목별 작가 매핑
- `problem_A5.py`: 도서 정가에 따른 가격 범위 분류

---

### ✅ 파일별 핵심 기능들

### `problem_A1.py`

- `data['item']` 리스트에서 도서 제목(`title`)만 추출하여 리스트로 저장하기
- 전체 도서 제목을 한 번에 출력하기

### `problem_A2.py`

- 도서의 판매가(`priceSales`)를 리스트로 모아 평균 가격 계산하기
- `sum()`과 `len()` 함수를 이용한 평균 계산 방식 사용

### `problem_A3.py`

- 고객 리뷰 순위(`customerReviewRank`) 데이터를 수집하여 평균값 계산하기

### `problem_A4.py`

- 각 도서의 제목과 저자(`author`) 정보를 `dict` 형식으로 저장
- 제목과 작가를 깔끔한 형식으로 출력하기

### `problem_A5.py`

- 도서 정가(`priceStandard`)를 기준으로 가격대를 세 범주로 분류하기
  - 1만원 미만
  - 1만원 이상 2만원 미만
  - 2만원 이상
- 각 가격 범주에 해당하는 도서 제목들을 출력하기

---

### ✏️ 학습한 내용

- `pathlib.Path`를 활용해 파일 경로를 설정하는 방법과, 경로 존재 여부를 체크하는 방법
- `json.load()`를 통한 JSON 데이터 파싱
- 리스트와 딕셔너리를 활용한 데이터 분류 및 통계 처리
- 조건문과 반복문을 통한 정보 추출 및 출력 포맷 구성

---

### 🥲 어려웠던 점

- 파일 경로 설정 시 처음에 상대 경로가 잘못 설정되어 있어 오류 찾는 데 시간이 조금 걸렸다.
- JSON 데이터의 중첩 구조를 처음 마주했을 때 원하는 키에 정확히 접근하는 과정이 쉽지 않았다. 저번 실습 시간에 배운 `pprint` 함수를 이용해 데이터 구조를 출력해서 직접 보면서 접근 코드를 작성하는 방법으로 해결할 수 있었다.
- 도서 정보에 일부 값이 누락되어 있을 가능성을 고려하지 않고 진행했을 때 오류가 발생할 수 있음을 깨달았다.

---

### ✨ 새로 배운 개념

- `Path.exists()`를 통해 간결하게 파일 존재 여부를 확인할 수 있다는 점을 학습했다.
- `Path.open()`은 `open()` 함수보다 객체지향적으로 파일을 열 수 있는 방식이며, 실무에서 가독성이 높다는 점을 체감했다.
- `json.load()`는 파일 객체를 읽어 딕셔너리 형태로 변환해주며, `json.loads()`는 문자열을 변환할 때 사용된다는 점을 구분했다.
- 도서 가격, 제목 등 특정 필드에 접근하기 위해 `.get()`을 사용하면 KeyError를 방지할 수 있다는 사실을 새로 알게 되었다.

---

### 💬 느낀 점

- 단순한 파일 읽기/쓰기 작업을 넘어서 JSON 데이터를 다루며 실제 API나 웹 크롤링 데이터와 유사한 구조를 경험해볼 수 있어 유익했다.
- 실습을 통해 데이터 전처리, 조건문, 출력 형식 등 기본적인 데이터 처리 능력을 향상시킬 수 있었다.
- 하나의 파일을 기반으로 다양한 문제 해결 방법을 탐색하면서 작은 코드 조각들이 실용적인 분석 도구가 될 수 있음을 느꼈다.
- JSON과 같은 구조화된 데이터를 다룰 때, 파일 입출력과 데이터 추출 능력이 중요한 기본기임을 다시금 깨달았다.

---

## 그룹 B

### 요구사항 번호: F06, F07, F08, F09, F10

---

### 📁 사용한 파일 목록

- `problem_B1.py`: 어린이 도서가 아닌 책 필터링
- `problem_B2.py`: 출판사별 도서 수 집계
- `problem_B3.py`: 카테고리별 도서 수 및 평균 가격 집계
- `problem_B4.py`: 최신 도서 10권 정렬 및 출력
- `problem_B5.py`: 할인율 기준 상위 5권 도서 출력

---

### ✅ 파일별 핵심 기능들

### `problem_B1.py`

- `'categoryName'` 필드에 `'어린이'`가 포함되지 않은 도서만 필터링하기
- 도서 제목과 카테고리를 함께 출력하기

### `problem_B2.py`

- `'publisher'` 값을 기준으로 출판사별 도서 수를 집계하기
- 딕셔너리를 활용하여 출판사명(key)과 권수(value)를 계산하기

### `problem_B3.py`

- `'categoryName'` 별로 도서 수와 `'priceSales'` 총합을 누적하기
- 평균 가격은 도서 수로 나누어 소수점 둘째 자리까지 출력할 것!

### `problem_B4.py`

- `'pubDate'`를 기준으로 내림차순 정렬하기
- 가장 최신 도서 10권을 추출하여 제목과 출판일 출력하기

### `problem_B5.py`

- `'priceStandard'`와 `'priceSales'`를 활용해 할인율 계산하기
- 할인율이 높은 순으로 정렬 후, 상위 5권 도서의 제목과 할인율 출력하기

---

### ✏️ 학습한 내용

- `sorted()` 함수의 `key` 매개변수를 이용한 정렬 알고리즘 적용법
- 문자열 기준의 날짜 데이터를 정렬에 적용하는 실전 활용법

---

### 🥲 어려웠던 점

- `'pubDate'`가 문자열이라 날짜로서 직접 비교가 안된다는 점이 초반에는 헷갈렸고, 정렬 결과의 정확성을 확인하기 위해 수작업 검증이 필요했다ㅠㅠ
- 할인율 계산 시 0으로 나눠지는 경우나 타입 오류(정수 vs 실수) 발생 가능성을 고려하지 않아 처음엔 오류가 났다.
- 도서 수, 가격 평균, 할인율 등의 계산 결과가 시각적으로 깔끔하게 출력되도록 포맷팅 처리에도 신경을 써야 했다. 예전 실습 때 심화 학습으로 공부했던 `f-string` 포맷팅 방법을 이용해 소수점 둘째 자리까지 출력하도록 하였다.

---

### ✨ 새로 배운 개념

- `lambda` 함수를 `sorted()`의 `key`에 활용하는 법
- 리스트의 특정 조건 필터링(`if '어린이' not in ...`) 로직
- `.items()`와 `.get()`을 통한 딕셔너리 순회와 안전한 접근 방식
- 할인율 계산 공식: `((정가 - 판매가) / 정가) * 100`

---

### 💬 느낀 점

- 단순 출력에 그치지 않고, 데이터에 의미를 부여하는 과정(예: 할인율 정렬, 최신 정렬, 카테고리별 평균 계산 등)이 실제 데이터 분석에서 얼마나 중요한지를 느낄 수 있었다.
- 반복적인 패턴을 다양한 변수에 적용하며 파이썬의 유연한 문법에 익숙해질 수 있었다.
- 오류 처리를 추가하거나 확장 기능을 붙이면 더욱 실무에 가까운 기능으로 발전시킬 수 있을 것 같다는 생각이 들었다.
- 프로젝트를 통해 `pathlib`, `json`, `dict`, `sorted()` 등 데이터 분석 시 자주 사용하는 파이썬 기능을 체계적으로 연습할 수 있어 유익했다.

---

## 그룹 C

### 요구사항 번호: F11, F12, F13

### 📁 사용한 파일 목록

- `problem_C1.py`: 도서를 월별로 분류하여 평균 가격 및 도서 수 통계 출력
- `problem_C2.py`: 카테고리별 도서 정보를 구조화하여 JSON 파일로 저장
- `problem_C3.py`: 시리즈 정보를 기준으로 도서를 분류하고 새로운 JSON 파일 생성

---

### ✅ 파일별 핵심 기능들

### `problem_C1.py`

- `books_2000.json` 데이터를 월별(`%m`)로 분류하기
- 각 월에 포함된 도서의 제목, 가격 정보를 수집하기
- 평균 가격(`priceSales`)을 계산하여 월별로 출력하기
- `datetime`, `collections.defaultdict`, `statistics.mean` 활용

### `problem_C2.py`

- `books_2000.json` 데이터를 카테고리 ID 기준으로 분류하기
- `categoryId` + `categoryName`을 키로 사용해 도서 리스트 구성하기
- 도서 정보는 제목, 작가, 출판사, 출판일, ISBN, 가격을 포함
- 최종 결과를 `category_books.json` 파일로 저장하기

### `problem_C3.py`

- `books_500.json`에서 시리즈 정보가 있는 도서만 필터링하기
- `seriesId` 기준으로 도서를 묶어 하나의 시리즈 단위로 구성할 것!
- 제목, 저자, 링크, ISBN 등 필드를 담아 `series.json` 파일로 저장하

---

### ✏️ 학습한 내용

- 날짜 형식(`%Y-%m-%d`)의 문자열 데이터를 `datetime`으로 파싱하고, 월 단위로 그룹화하는 방법
- JSON 데이터를 다차원 구조로 재정렬하고, 조건에 따라 필터링/그룹핑하는 로직 구성법
- `defaultdict(list)`를 활용한 데이터 자동 분류 방식
- JSON 출력 시 한글 깨짐 방지를 위한 `ensure_ascii=False` 설정
- 구조화된 데이터를 외부 JSON 파일로 안전하게 저장하는 `json.dump` 사용법

---

### 🥲 어려웠던 점

- 생성형 AI인 GPT를 사용해서 코드를 구현해보았는데, 요청한 기능에 대해서는 정확하고 편리하게 코드를 작성해주어 작업 효율이 높았지만, 이후 추가 기능을 구현할 때에는 우리가 직접 코드를 덧붙이는 방식이었기 때문에 GPT가 작성한 코드를 이해하고 구조를 파악한 뒤 변형하는 과정이 조금 어려웠다.
  특히 GPT가 효율적으로 코드를 작성해주느라 새로운 함수들을 도입하는 경우가 많았어서, 그 함수들을 이해하는데 시간을 많이 썼다.
- `pubDate` 필드가 `"YYYY-MM-DD"` 형식이 아닌 경우도 있어 `strptime()`에서 예외가 발생했고, 이를 try-except로 처리해야 했다.
- `categoryId`, `seriesId`는 숫자형이지만 딕셔너리 키로 사용할 때 문자열 변환을 일관되게 하지 않아 오류가 발생했다. 오류가 왜 발생하는지 이해하는데 오래걸렸고, 결국`str()` 을 쓰는 시점을 수정해 오류를 고칠 수 있었다.
- 도서마다 포함된 필드가 조금씩 달라, `.get()`을 사용해 키 오류를 방지해야 했다.
- 생성된 JSON 파일 구조가 너무 깊거나 반복되는 키를 만들지 않도록 설계에 신경을 써야 했다.

---

### ✨ 새로 배운 개념

- `datetime.strptime()`를 이용한 날짜 파싱과 `.strftime()`을 통한 포맷 변환
- `defaultdict`를 이용한 키 존재 여부 없이 리스트 초기화하는 방식
- JSON 파일 생성 시 `indent` 옵션으로 가독성 높이기
- Python 딕셔너리를 기반으로 계층형 JSON을 구성하는 로직 설계

---

### 💬 느낀 점

- 단순히 데이터를 출력하는 수준을 넘어서, 데이터를 실제 구조화하고 외부 시스템에서 활용 가능한 형태로 만드는 과정을 경험할 수 있었다.
- 생성형 AI를 직접 활용하지는 않았지만, 이를 활용해 자동으로 코드를 생성해보며 코드 검토 및 디버깅 실력이 향상되었다.
- 특히 시리즈 분류 작업은 실제 출판사, 콘텐츠 서비스에서 사용할 수 있는 기능이라 매우 흥미롭게 느껴졌다.

---

## 심화 학습

### 요구사항 번호: F14, F15, F16

### 📁 사용한 파일 목록

- `problem_D1.py`: 도서 데이터를 요약하고 생성형 AI에 인사이트 요약 요청
- `problem_D2.py`: 할인율과 판매량 관계 분석, 저자별 생산성 및 추가 분석 항목(카테고리별 통계) 도출
- `problem_D3.py`: 생성형 AI를 활용하여 가상의 책 정보 생성 및 JSON 저장

---

### ✅ 파일별 핵심 기능들

### `problem_C1.py`

- 도서 데이터를 `"어린이"` 포함 여부에 따라 어린이 / 비어린이 도서로 구분하기
- 각 그룹에 대해 다음 정보를 수집:
  - 평균 정가(`priceStandard`)
  - 카테고리별 도서 수 집계 → TOP3 추출
- 결과는 `pprint()`로 출력하며, 생성형 AI에 전달 가능한 요약 형태로 구성하기
- 요약 요청 결과를 주석으로 함께 정리하기

### `problem_C2.py`

- 할인율 계산: `(정가 - 판매가) / 정가 * 100`
- 전체 평균 할인율 및 평균 판매량 출력하기
- 저자별 도서 수, 평균 판매량 분석 → 생산성 높은 저자 TOP 5 추출
- 카테고리별 평균 할인율 계산 → 할인율 높은 카테고리 TOP 5 출력

### `problem_C3.py`

- GPT로부터 생성한 도서 정보를 JSON 형태로 구현하기
- 포함 필드: 제목, 저자, 출판사, 출판일, 가격, ISBN, 카테고리, 시리즈 등
- `new_book.json` 파일로 저장하며 `ensure_ascii=False`, `indent=4` 옵션 활용

---

### ✏️ 학습한 내용

- AI에 요약 요청을 하기 위한 프롬프트 구성 능력
- 할인율 계산 및 통계 분석(`mean`, `sorted`, `defaultdict`)을 활용한 관계 분석
- 생성형 AI가 만든 데이터를 구조화된 JSON 포맷으로 변환하는 과정 전반에 대해 학습

---

### 🥲 어려웠던 점

- 처음에는 도서를 "성인 도서"와 "성인 도서가 아닌 것들"로 분류하려고 했지만, 실제 데이터를 분석해보니 성인 도서의 수가 너무 적어 의미 있는 통계나 인사이트를 도출하기 어려웠다. 우리는 처음에 도서가 '성인용'과 '어린이용'으로 명확하게 나뉠 것이라 생각했지만, 알라딘 Open API 매뉴얼을 찾아보니 `adult` 속성은 실제로 '성인 등급 여부(true인 경우 성인 등급 도서)'를 의미하는 필드였다. 결국 우리가 의도한 방식대로 분류가 되지 않았던 것이다.
  이후 고민 끝에 `"어린이"`라는 키워드를 `categoryName` 필드에서 포함 여부로 판단해 `"어린이 도서"`와 `"비어린이 도서"`로 다시 기준을 설정했다. 이 과정에서 필터링 조건뿐 아니라 출력 용어, 구조 전반도 수정해야 했고, 의외로 손이 많이 갔다.
  이 경험을 통해, 데이터 분류 기준을 세우기 전에 먼저 전체 데이터 구조와 각 필드의 의미를 충분히 이해하고 세밀하게 파악하는 것이 중요하다는 점을 깨달았다.
- 생성형 AI의 출력 결과가 항상 구조적으로 완벽하진 않기 때문에, 이를 적절히 수정하고 실용적인 형태로 정리하는 데 추가 시간이 필요했다.
- 데이터가 완전하지 않거나 필드가 누락된 경우 `.get()`을 적극적으로 활용해야 오류 없이 분석이 가능했다.
- 할인율 계산에서 0으로 나누는 경우를 처리하지 않으면 런타임 오류가 발생했으며, 이러한 예외 처리 로직의 필요성을 느꼈다.

---

### ✨ 새로 배운 개념

- `statistics.mean()`을 활용한 통계 처리와 `lambda` 기반 정렬(`sorted(key=...)`)
- 생성형 AI의 출력 결과를 실제 프로그래밍 환경에 맞게 다듬는 역량
- 요약을 위한 핵심 지표(평균 가격, 카테고리 빈도, 할인율 등) 정의 방법
- AI가 만든 구조적 텍스트를 JSON으로 변환할 때 주의해야 할 포맷 기준
- 프롬프트 작성 시 데이터 기반 요약과 스토리텔링 중심 인사이트 구성의 차이

---

### 💬 느낀 점

- 생성형 AI를 코드 구현뿐 아니라 데이터 분석 파트너로 활용할 수 있다는 가능성을 체감했다.
- GPT의 출력물은 초안으로서는 유용하지만, 완성도 높은 결과를 만들기 위해서는 사람의 해석, 수정 능력이 반드시 필요했다.
- 이번 심화 과제를 통해 데이터 해석 + AI 활용 + 코드 구현을 하나로 연결하는 역량이 좀 더 늘었다고 느꼈다.