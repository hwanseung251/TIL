## 1. 학습 목표

- **개인화된 AI 모델**을 만들기 위한 적응학습(Fine-tuning, Prompt Tuning)의 개념 이해
- **합성 데이터(Synthetic Data)**의 필요성과 생성 방법 파악
- **현실 데이터의 한계**를 극복하기 위한 실질적 접근법 학습
- **AI 리터러시 플러스(++)**: AI를 단순히 활용하는 것을 넘어 **‘내 입맛에 맞게 바꾸는 능력’**을 갖추는 것

---

## 2. 강의 도입 – 현실적인 데이터 문제 인식

> “AI 모델은 결국 데이터를 먹고 자랍니다.
> 
> 
> 그런데 현실에서 그 데이터를 얻는 게 가장 어렵습니다.”
> 

### 2.1 데이터 수집의 어려움

- 의료 영상, 위성 이미지, 3D, 동작 추적 등은
    
    **개인정보 문제·고가 장비·취득 불가 환경**으로 인해 현실적으로 확보가 어려움.
    
- 기관 지원이 없으면 **데이터 구축 자체가 불가능**한 경우도 많음.
- 이런 상황에서 “모델 성능이 떨어진다”는 건 **데이터 결핍의 직접적 결과**다.

---

## 3. 개인화 모델의 필요성과 Fine-tuning

> “파운데이션 모델의 진짜 성능은 Fine-tuning을 했을 때 나옵니다.”
> 

### 3.1 왜 Fine-tuning이 필요한가?

- 파운데이션 모델은 방대한 데이터로 학습되지만, **‘범용적’**이다.
- 도메인 특화 작업(예: 의료, 관광, 위성 판독 등)에서는 성능 저하가 발생한다.
- **소량의 도메인 데이터로 추가 학습(Fine-tuning)** 하면
    
    모델이 빠르게 적응하며 정확도가 상승한다.
    

### 3.2 Fine-tuning의 장점

- 적은 데이터로 고성능 달성 가능
- GPU 및 리소스 절감
- 도메인 특화 개인화 모델 생성 가능

---

## 4. AI 리터러시++ : “AI를 내 입맛대로 바꾸는 능력”

> “이제는 AI를 잘 쓰는 수준을 넘어,
> 
> 
> **AI를 내 입맛대로 바꿔 쓸 수 있어야 합니다.**”
> 

### 4.1 리터러시++의 구성 요소

- AI 작동 원리 이해
- 생성 정보의 비판적 분석
- 데이터 구조 및 프롬프트 엔지니어링 이해
- AI를 통한 문제 해결 능력
- 윤리적 판단 및 데이터 책임성
- 그리고 핵심: **AI를 재조정(Fine-tuning)**할 수 있는 역량

---

## 5. Fine-tuning의 원리 요약

### 5.1 Gradient Descent의 재활용

> “Fine-tuning도 결국은 Gradient Descent,
> 
> 
> 손실함수를 줄이는 방향으로 가는 겁니다.”
> 

$W \leftarrow W - \eta \frac{\partial L}{\partial W}$

- 손실함수 LLL 을 미분해 기울기(Gradient)를 계산
- 그 반대 방향으로 가중치 W 를 업데이트
- 학습률은 그 이동 폭을 결정 (너무 크면 발산, 너무 작으면 정체)

> “Fine-tuning에서는 러닝레이트를 작게 잡아야 합니다.
> 
> 
> 이미 잘하는 모델을 망가뜨리지 않으려면요.”
> 

---

## 6. 학습률(Learning Rate)과 수렴

### 6.1 러닝레이트의 역할

- 학습률이 **너무 크면** 기존 지식을 잃음 (Catastrophic Forgetting)
- 학습률이 **너무 작으면** 학습 속도 저하, 로컬 미니마에 갇힘
- 따라서 Fine-tuning은 “**작은 러닝레이트에서 시작**”해야 함

> “큰 모델일수록 학습률 설정이 예술입니다.
> 
> 
> 전문가들도 손맛으로 조율합니다.”
> 

---

## 7. 파라미터 효율적 파인튜닝 (PEFT)

> “모델이 너무 크면 전체를 다 건드릴 수 없습니다.
> 
> 
> 필요한 부분만 튜닝하세요.”
> 

### 7.1 개념

- 모델 전체를 다시 학습하는 대신,
    
    **일부 파라미터만 학습하거나 추가 모듈만 조정**하는 방식.
    
- GPU 메모리 절감, 빠른 학습, 적은 데이터로도 가능.

### 7.2 대표 기법

| 기법 | 개요 | 특징 |
| --- | --- | --- |
| **LoRA (Low-Rank Adaptation)** | 기존 레이어 옆에 소형 학습 모듈을 붙임 | 기존 가중치는 고정, 추가 모듈만 학습 |
| **Prefix Tuning** | 입력 앞에 학습 가능한 토큰 추가 | 텍스트 기반 태스크 적합 |
| **Prompt Tuning** | 사람이 아닌 **모델이 프롬프트를 학습**하도록 함 | 프롬프트 자동 최적화 |

> “LoRA는 파운데이션 모델 옆에 살짝 학습 모듈을 붙이는 겁니다.
> 
> 
> **모델은 그대로 두고 LoRA만 학습**하니까 훨씬 효율적이죠.”
> 

---

## 8. Prompting vs Fine-tuning

| 구분 | Prompting | Fine-tuning |
| --- | --- | --- |
| 개념 | 입력문장에 지시나 예시를 추가 | 모델 자체를 재학습 |
| 데이터 요구 | 거의 없음 | 소량 필요 |
| 계산량 | 낮음 | 다소 높음 |
| 지식 반영 | 매 입력마다 처리 | 내재화되어 빠른 응답 |
| 예시 | “이 이미지를 설명해줘” | “이미지 캡션 생성 모델로 재학습” |

> “Fine-tuning은 ‘내재화된 프롬프트’입니다.
> 
> 
> 매번 말 안 해도 모델이 이미 알고 있는 상태로 만드는 거예요.”
> 

---

## 9. Prompt Engineering의 한계와 자동화

### 9.1 기존의 문제

- 사람이 직접 프롬프트 설계 → **감(감각)에 의존**
- “이 프롬프트가 좋은가요?”라는 판단도 경험 기반
- 실무 적용 시 **일관성 부족, 재현성 저하**

### 9.2 자동 프롬프트 튜닝의 등장

- **Soft Prompt (가상 토큰)** 도입
- 사람이 입력한 문장을 **학습 가능한 숫자 벡터로 대체**
- 이 벡터가 역전파로 최적화됨

$\text{Input} = [P_1, P_2, ..., P_k, X]$

> “Soft Token은 사람이 해석할 수 없어요.
> 
> 
> 대신 모델이 스스로 ‘좋은 프롬프트’를 배웁니다.”
> 

---

## 10. 합성 데이터(Synthetic Data)의 필요성

> “리얼 데이터를 얻기 어렵다면,
> 
> 
> 그래픽스로 ‘만들면’ 됩니다.”
> 

### 10.1 정의

- 실제 촬영이나 수집이 아닌, **인위적으로 생성된 데이터**
- 예: 3D 그래픽, 시뮬레이션, GAN/Diffusion 기반 이미지

### 10.2 활용 이유

- **데이터 부족·비용 문제 해결**
- **희귀 케이스 보완** (예: 특정 질병 영상)
- **윤리적 이슈 회피** (개인정보, 저작권 문제)

> “합성 데이터는 더 이상 보조재가 아닙니다.
> 
> 
> AI 학습의 필수 재료입니다.”
> 

---

## 11. 요약 – AI 실무 역량으로의 확장

| 구분 | 내용 |
| --- | --- |
| **핵심 역량** | AI를 직접 Fine-tuning할 수 있는 능력 |
| **데이터 확보 전략** | 현실+합성 데이터 혼합 활용 |
| **모델 활용 방식** | Prompt → Fine-tuning → PEFT 순 단계별 적용 |
| **러닝레이트 전략** | 작은 값으로 시작, 점진 조정 |
| **AI 리터러시++** | 단순 사용자 → ‘모델 조정자’로의 성장 |

---

## 12. 교수님의 마무리 메시지

> “파운데이션 모델의 시대에
> 
> 
> **AI를 잘 쓰는 사람과, 바꿀 줄 아는 사람**의 차이는 큽니다.”
> 
> “데이터가 없다고 멈추지 마세요.
> 
> **합성 데이터로 길을 여는 게 진짜 AI 개발자의 자세입니다.**”
>