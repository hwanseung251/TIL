# CNN의 철학적 발전: 인간 시각에서 딥러닝으로

## 1. 완전연결 신경망의 한계에서 출발하다

초기의 인공신경망은 **모든 입력이 모든 노드에 연결되는 구조(Fully Connected Layer)**였다.

하지만 이 구조는 **이미지 데이터에 맞지 않는** 심각한 한계를 가지고 있었다.

- **공간 구조를 무시한다**:
    
    픽셀 간의 위치적 관계가 사라진다.
    
    이미지는 공간적 구조가 중요한데, 완전연결은 그걸 납작하게 펴버린다.
    
- **파라미터 폭발**:
    
    28×28 이미지(784차원)를 은닉층 1,000개에 연결하면 78만 개의 가중치가 생긴다.
    
    이건 학습 자체가 불가능할 정도로 비효율적이다.
    
- **위치 불변성 부족**:
    
    고양이가 왼쪽에 있느냐 오른쪽에 있느냐에 따라 완전히 다른 입력으로 본다.
    

> 교수님 설명
> 
> 
> “Fully Connected는 이미지를 ‘눈 감고 숫자만 보는’ 방식이에요.
> 
> 시각 정보는 구조적으로 연결되어 있는데, 그걸 다 잘라서 섞어버리니까
> 
> 공간적 의미를 이해하지 못하는 겁니다.”
> 

이런 문제의식이 바로 **Convolutional Neural Network(CNN)** 의 출발점이었다.

---

## 2. Convolution의 철학: 지역성과 가중치 공유

CNN은 인간의 시각 피질을 모방했다.

우리의 시각 피질에는 **Receptive Field(수용장)**이라는 개념이 있다 —

각 뉴런은 시야 전체가 아니라 **특정한 작은 영역**에만 반응한다.

CNN도 마찬가지로, 한 번에 전체 이미지를 보는 대신

**국소적인 부분(Local Region)**을 살피며 특징을 추출한다.

$y_{i,j} = \sum_{m,n} x_{i+m, j+n} \cdot w_{m,n}$

이 식은 **커널(필터)**이 입력 이미지 위를 슬라이딩하며

각 영역의 “특징”을 찾아내는 과정을 표현한다.

### 가중치 공유(Weight Sharing)

CNN의 또 다른 핵심 철학은 **‘같은 패턴은 어디에 있든 같은 방식으로 본다’**이다.

모든 위치에서 같은 커널을 사용함으로써,

하나의 특징(예: 눈, 테두리)을 탐지하는 공통 필터를 학습한다.

> 교수님 설명
> 
> 
> “사람은 ‘눈’이라는 특징을 얼굴 어디서나 인식할 수 있죠.
> 
> CNN도 마찬가지예요.
> 
> 필터 하나가 그 ‘눈’을 배우면, 이미지 어디서든 눈을 찾을 수 있습니다.”
> 

[수업 포인트]

- CNN은 **공간적 패턴 학습**이라는 새로운 사고방식을 제시했다.
- 단순히 파라미터를 줄이려는 기술적 발명이 아니라,
    
    **‘정보를 어떻게 바라볼 것인가’에 대한 철학적 전환**이었다.
    

---

## 3. Pooling: 불변성의 시작

Convolution은 세밀한 특징을 잡아내지만,

위치 변화에는 여전히 민감하다.

따라서 CNN은 **Pooling Layer**를 통해

특징을 요약하고, **위치 변화에 불변한 표현(Invariant Representation)**을 만든다.

$y_{i,j} = \max_{(m,n) \in R_{i,j}} x_{m,n}$

### Max vs Average Pooling

- **Max Pooling**은 지역 내의 **가장 강한 신호**만 남긴다.
    
    → 가장 두드러진 특징을 유지한다.
    
- **Average Pooling**은 평균을 취해 **전체적인 경향**을 유지한다.

> 교수님 설명
> 
> 
> “Pooling은 단순히 차원을 줄이는 게 아닙니다.
> 
> 마치 사진의 초점을 맞추듯, 중요한 정보만 남기는 과정이에요.”
> 

[수업 포인트]

- Pooling은 **‘복잡성을 줄이면서 의미를 남기는’ 인지적 압축 과정**이다.
- 이로써 모델은 ‘어디에 있느냐’보다 ‘무엇이 있느냐’에 집중하게 된다.

---

## 4. ReLU: 학습에 생명력을 불어넣다

활성화 함수 ReLU(Rectified Linear Unit)는

CNN의 학습을 **비약적으로 가속시킨 결정적 요소**다.

$f(x) = \max(0, x)$

ReLU는 음수를 0으로 만들고, 양수만 그대로 통과시킨다.

이는 계산을 단순화하면서도 Gradient가 사라지지 않게 한다.

> 교수님 설명
> 
> 
> “Sigmoid는 부드럽지만 너무 완만합니다.
> 
> 반면 ReLU는 단순하지만 ‘살아있어요’.
> 
> 중요한 신호에는 즉각 반응하고, 쓸모없는 건 버려버리죠.”
> 

[수업 포인트]

- ReLU는 **계산 효율성과 생물학적 유사성**을 동시에 잡은 선택이었다.
- “모델이 스스로 선택적으로 반응하는 뇌”의 시작이었다.

---

## 5. CNN의 계층적 구조

$입력 → [Conv + ReLU] → [Pooling] → [Conv + ReLU] → [Pooling] → [FC + Softmax]$

CNN은 층이 깊어질수록 더 복잡하고 추상적인 특징을 배운다.

처음에는 **모서리**, 그다음은 **형태**, 마지막에는 **객체 전체**로 확장된다.

> 교수님 설명
> 
> 
> “초기 층은 ‘눈썹’을 배우고,
> 
> 중간 층은 ‘얼굴’을,
> 
> 마지막 층은 ‘사람’을 인식하게 됩니다.
> 
> 이런 계층적 학습이 바로 CNN의 강점이에요.”
> 

---

## 6. 모델의 진화: 시대별 설계 철학

---

### (1) LeNet – CNN의 태동 (1998)

**철학**

- “이미지도 신경망으로 볼 수 있다.”
- Convolution + Pooling의 개념을 정식으로 제안.

**교수님 설명**

> “LeNet은 딥러닝의 씨앗이에요.
> 
> 
> 하지만 당시에는 컴퓨팅 파워가 너무 부족했습니다.
> 
> 그럼에도 ‘로컬 필터’라는 개념을 세운 건 혁명적이었죠.”
> 

[수업 포인트]

- CNN의 ‘핵심 골격’을 만든 첫 모델.
- GPU 시대를 기다리고 있었던 **시대의 선구자**.

---

### (2) AlexNet – 깊이의 발견 (2012)

**철학**

- “깊게 쌓으면 더 똑똑해질 수 있다.”
- ReLU, Dropout, Data Augmentation, GPU 병렬 학습을 활용하여
    
    딥러닝 부활의 서막을 열었다.
    

**교수님 설명**

> “AlexNet은 LeNet이 못다 한 꿈을 GPU가 이뤄준 모델이에요.
> 
> 
> 단순히 구조를 깊게 만든 게 아니라,
> 
> 데이터를 ‘감각적으로 이해하는 능력’을 부활시켰습니다.”
> 

[수업 포인트]

- ReLU로 학습 속도 6배 향상.
- Dropout으로 과적합 해결.
- *‘컴퓨팅 자원의 혁신이 곧 모델의 혁신’**임을 보여줌.

---

### (3) VGG – 규칙의 미학 (2014)

**철학**

- “복잡함을 통일된 규칙으로 단순화하자.”
- 모든 Conv를 3×3으로 통일하고,
    
    Pooling을 2×2로 고정하여 구조적 일관성을 확보했다.
    

**교수님 설명**

> “AlexNet은 좋았지만, 층마다 구조가 제각각이었어요.
> 
> 
> 필터 크기도 다르고, 채널 수도 다 다르니까
> 
> 사람이 일일이 설계해야 했습니다.
> 
> VGG는 이런 혼란을 ‘하나의 규칙’으로 해결했어요.
> 
> 모든 걸 3×3으로 통일하고, 그걸 반복했죠.
> 
> 즉, 사람이 일일이 고민하지 않아도 되는 구조였던 겁니다.”
> 

[수업 포인트]

- **일관된 설계 원칙의 시작.**
- “모델 설계가 ‘예술’에서 ‘공학’으로 전환된 순간.”
- 이후 ResNet, EfficientNet 등 모든 CNN이 VGG의 규칙성을 계승했다.

---

### (4) GoogLeNet – 폭의 확장 (2014)

**철학**

- “서로 다른 시야로 동시에 보자.”
- Inception Module을 통해 1×1, 3×3, 5×5 필터를 병렬로 배치.
    
    다양한 크기의 특징을 동시에 포착한다.
    

**교수님 설명**

> “사람은 사물을 볼 때 한 거리만 보지 않아요.
> 
> 
> 멀리, 중간, 가까이 — 여러 스케일을 동시에 본다고요.
> 
> GoogLeNet은 그걸 수학적으로 구현한 모델입니다.”
> 

[수업 포인트]

- **다중 시야(Multi-scale) 학습**의 시작.
- 1×1 Conv로 차원 축소 + 비선형성 강화.
- 연산량은 줄이고 표현력은 확장.

---

### (5) ResNet – 잊지 않는 학습 (2015)

**철학**

- “더 깊이 쌓되, 잊지 말자.”
- Skip Connection을 통해 Gradient 소실 문제를 해결.
    
    $y = F(x) + x$
    

**교수님 설명**

> “VGG 이후 연구자들은 ‘깊으면 무조건 좋다’고 생각했어요.
> 
> 
> 그런데 20층이 넘어가면 오히려 정확도가 떨어지기 시작했습니다.
> 
> He 교수는 여기서 ‘아, 문제는 깊이가 아니라 **기억의 단절**이구나’라고 본 거예요.
> 
> 그래서 ResNet은 입력을 그냥 더했습니다.
> 
> 학습이 아니라 복기를 한 거죠.
> 
> 모델이 ‘내가 이미 아는 걸 다시 배워야 할 필요는 없잖아?’ 하고 생각하게 된 겁니다.”
> 

[수업 포인트]

- “ResNet은 딥러닝의 기억력 보존 장치다.”
- **‘무엇을 더 배울 것인가’가 아니라 ‘무엇을 안 배워도 되는가’를 정의했다.**

---

### (6) MobileNet – 효율의 철학 (2017)

**철학**

- “작고 가볍게, 그러나 정확하게.”
- Depthwise Separable Convolution을 통해 연산량을 획기적으로 줄임.

$Conv(x) = DepthwiseConv(x) + PointwiseConv(x)$

**교수님 설명**

> “모바일 환경에서는 연산 하나하나가 전력이에요.
> 
> 
> MobileNet은 ‘작은 뇌로 큰 생각을 하는 법’을 보여준 모델입니다.”
> 

[수업 포인트]

- 기존 Conv 대비 연산량 약 1/8.
- 실시간 추론 가능.
- **‘성능 중심’에서 ‘자원 효율 중심’으로의 패러다임 전환.**

---

## 7. CNN의 진화 요약

| 시대 | 모델 | 철학 | 혁신 포인트 |
| --- | --- | --- | --- |
| 1998 | LeNet | 시각 피질의 모방 | CNN의 기본 구조 제시 |
| 2012 | AlexNet | 깊이와 GPU의 결합 | ReLU, Dropout, Data Augmentation |
| 2014 | VGG | 단순한 규칙의 반복 | 구조적 일관성, 설계의 표준화 |
| 2014 | GoogLeNet | 다중 시야 | Inception 모듈, 효율적 병렬화 |
| 2015 | ResNet | 기억의 복기 | Skip Connection, Residual Learning |
| 2017 | MobileNet | 자원의 효율성 | Depthwise Separable Conv |

---

## 8. 교수님의 마무리

> “CNN의 발전은 단순한 성능 경쟁이 아니에요.
> 
> 
> 인간이 시각을 이해하는 철학이 점점 정교해진 겁니다.”
> 
> “LeNet은 ‘보는 법’을 배웠고,
> 
> AlexNet은 ‘깊게 보는 법’을,
> 
> ResNet은 ‘잊지 않고 보는 법’을,
> 
> MobileNet은 ‘가볍게 보는 법’을 배웠죠.”
> 
> “이제 여러분이 할 일은, **이 철학을 데이터에 맞게 다시 설계하는 것**입니다.”
>